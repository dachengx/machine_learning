{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316e2c2f-d956-4974-bfd3-123d721f8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174ef68e-ea90-4b3c-bdfd-7ac48098fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "GRID_SIZE = 4\n",
    "GOAL = (3, 3)\n",
    "START = (0, 0)\n",
    "\n",
    "# Hyperparameters\n",
    "ALPHA = 0.1      # Learning rate\n",
    "GAMMA = 0.9      # Discount factor\n",
    "EPSILON = 0.2    # Exploration rate\n",
    "EPISODES = 100\n",
    "MAX_STEPS = 20\n",
    "\n",
    "# Q-table: maps (state, action) -> Q-value\n",
    "q_table = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f05e00-9d92-4b57-8499-56896193ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_key(x, y):\n",
    "    return (x, y)\n",
    "\n",
    "def get_q_value(state, action):\n",
    "    return q_table.get((state, action), 0.0)\n",
    "\n",
    "def set_q_value(state, action, value):\n",
    "    q_table[(state, action)] = value\n",
    "\n",
    "def select_action(state, epsilon):\n",
    "    \"\"\"Epsilon-greedy action selection\"\"\"\n",
    "    if random.random() < epsilon:\n",
    "        return random.randint(0, 3)  # Explore\n",
    "    else:\n",
    "        # Exploit: choose best action\n",
    "        actions = [0, 1, 2, 3]\n",
    "        return max(actions, key=lambda a: get_q_value(state, a))\n",
    "\n",
    "def execute_action(x, y, action):\n",
    "    \"\"\"Execute action and return new position\"\"\"\n",
    "    moves = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # Up, Down, Left, Right\n",
    "    dx, dy = moves[action]\n",
    "    nx, ny = x + dx, y + dy\n",
    "    \n",
    "    # Clamp to grid boundaries\n",
    "    nx = max(0, min(GRID_SIZE - 1, nx))\n",
    "    ny = max(0, min(GRID_SIZE - 1, ny))\n",
    "    \n",
    "    return nx, ny\n",
    "\n",
    "def train_episode():\n",
    "    \"\"\"Train one episode\"\"\"\n",
    "    # Random start position\n",
    "    x, y = random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1)\n",
    "    \n",
    "    for step in range(MAX_STEPS):\n",
    "        state = get_state_key(x, y)\n",
    "        action = select_action(state, EPSILON)\n",
    "        \n",
    "        # Execute action\n",
    "        nx, ny = execute_action(x, y, action)\n",
    "        next_state = get_state_key(nx, ny)\n",
    "        \n",
    "        # Calculate reward\n",
    "        if (nx, ny) == GOAL:\n",
    "            reward = 10\n",
    "        else:\n",
    "            reward = -0.1\n",
    "        \n",
    "        # Q-learning update\n",
    "        old_q = get_q_value(state, action)\n",
    "        max_next_q = max(get_q_value(next_state, a) for a in range(4))\n",
    "        new_q = old_q + ALPHA * (reward + GAMMA * max_next_q - old_q)\n",
    "        set_q_value(state, action, new_q)\n",
    "        \n",
    "        # Move to next state\n",
    "        x, y = nx, ny\n",
    "        \n",
    "        # Stop if goal reached\n",
    "        if (x, y) == GOAL:\n",
    "            break\n",
    "\n",
    "def test_agent():\n",
    "    \"\"\"Test the trained agent\"\"\"\n",
    "    x, y = START\n",
    "    path = [(x, y)]\n",
    "    \n",
    "    for step in range(15):\n",
    "        if (x, y) == GOAL:\n",
    "            break\n",
    "        \n",
    "        state = get_state_key(x, y)\n",
    "        action = select_action(state, 0)  # No exploration\n",
    "        x, y = execute_action(x, y, action)\n",
    "        path.append((x, y))\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cf3051-8ded-4f20-bfa4-36706b4505c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Episode 20/100\n",
      "Episode 40/100\n",
      "Episode 60/100\n",
      "Episode 80/100\n",
      "Episode 100/100\n",
      "\n",
      "Training complete!\n",
      "\n",
      "Testing agent path:\n",
      "Start: (0, 0), Goal: (3, 3)\n",
      "Path: (0, 0) -> (1, 0) -> (1, 1) -> (1, 2) -> (1, 3) -> (2, 3) -> (3, 3)\n",
      "Steps taken: 6\n",
      "\n",
      "Grid visualization:\n",
      "* . . . \n",
      "* * * * \n",
      ". . . * \n",
      ". . . G \n"
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "print(\"Training...\")\n",
    "for episode in range(EPISODES):\n",
    "    train_episode()\n",
    "    if (episode + 1) % 20 == 0:\n",
    "        print(f\"Episode {episode + 1}/{EPISODES}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "# Test the agent\n",
    "print(\"\\nTesting agent path:\")\n",
    "path = test_agent()\n",
    "print(f\"Start: {START}, Goal: {GOAL}\")\n",
    "print(f\"Path: {' -> '.join(str(p) for p in path)}\")\n",
    "print(f\"Steps taken: {len(path) - 1}\")\n",
    "\n",
    "# Display grid\n",
    "print(\"\\nGrid visualization:\")\n",
    "for i in range(GRID_SIZE):\n",
    "    for j in range(GRID_SIZE):\n",
    "        if (i, j) == GOAL:\n",
    "            print(\"G\", end=\" \")\n",
    "        elif (i, j) in path:\n",
    "            print(\"*\", end=\" \")\n",
    "        else:\n",
    "            print(\".\", end=\" \")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
